mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
dead<-length(which(r<=0.75))
shut<-ifelse( dead>=0.75*10,1,0)
s<-c(s,shut)
}
mean(s)
r<-runif(10,min=0.5,1)
r<-r[order(r)]
r
r[7]
r[7]>3/4
r<-runif(10,min=0.5,1)
>  r<-r[order(r)]
r<-runif(10,min=0.5,1),r<-r[order(r)]
r<-runif(10,min=0.5,1);r<-r[order(r)]
r
r[7]
r[which(r<3/4)]
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[7]>3/4
dead
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
live<-r[7]>3/4
shut<-ifelse( live==FALSE,1,0)
s<-c(s,shut)
}
s
mean(s)
s
live
shut
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
live<-r[7]>=3/4
shut<-ifelse( live==FALSE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
live<-r[7]>=3/4
shut<-ifelse( live==FALSE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
live<-r[7]>=3/4
shut<-ifelse( live==FALSE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
live<-r[7]>=3/4
shut<-ifelse( live==FALSE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
r
for(k in 8:10){ choose(10,k)*0.5^10}
for(k in 8:10){ s<-choose(10,k)*0.5^10}
s<-c()
for(k in 8:10){ s<-choose(10,k)*0.5^10}
s
for(k in 8:10){ s<-c(s,choose(10,k)*0.5^10)}
s<-c()
for(k in 8:10){ s<-c(s,choose(10,k)*0.5^10)}
s
sum(s)
r
which(r<=0.75)
length(which(r<=0.75))
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
shut
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s<-c()
for(k in 8:10){ s<-c(s,choose(10,k)*0.5^10)}
s
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s2<-c()
for(k in 8:10){ s<-c(s2,choose(10,k)*0.5^10)}
sum(s2)
s<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
s2<-c()
for(k in 8:10){ s2<-c(s2,choose(10,k)*0.5^10)}
sum(s2)
shut
sum(s)
mean(s)
sum(s2)
r
r[7]
s<-c()
a<-c()
for(i in 1:10000){
r<-runif(10,min=0.5,1)
r<-r[order(r)]
a<-c(a,r[7])
dead<-r[8]<=3/4
shut<-ifelse( dead==TRUE,1,0)
s<-c(s,shut)
}
mean(s)
mean(a)
r
r[5]
r[5]-r[8]
r[8]-r[5]
(r[8]-r[5])
(r[8]-r[5])*365
1/0.5
18.091*365
r<-runif(15,min=1,max=1)
r<-r[order(r)]
r
r<-runif(15,min=0,max=1)
r<-r[order(r)]
r
maxi<-r[length(r)]
M<-c()
##n = 15
for(i in 1:100){
r<-runif(15,min=0,max=1)
r<-r[order(r)]
maxi<-r[length(r)]
M<-c(M,maxi)
}
hist(M)
M
runif(15,0,1)
15*(runif(15,0,1))^14
hist(15*(runif(15,0,1))^14)
hist(15*(dunif(15,0,1))^14)
dunif(runif(15,0,1))
(15*(dunif(15,0,1))^14)
(15*(runif(15,0,1))^14)
M
dunif(M)
punif(M)
?punif
qunif(M)
M
hist(M
)
mean(M)
(15*M^14)
M
M
sapply(M,function(x) 15*x^(14))
dunif(M)
mean(M)
15/16
M<-c()
##n = 15
for(i in 1:10000){
r<-runif(15,min=0,max=1)
r<-r[order(r)]
maxi<-r[length(r)]
M<-c(M,maxi)
}
hist(M)
M
mean(M)
15/16
r
maxi
for(i in 1:10000){
r<-runif(15,min=0,max=1)
r<-r[order(r)]
maxi<-r[length(r)]
M<-c(M,maxi)
fxi<-15*maxi^(14)
FXI<-c(FXI,fxi)
}
hist(M)
M<-c()
FXI<-c()
##n = 15
for(i in 1:10000){
r<-runif(15,min=0,max=1)
r<-r[order(r)]
maxi<-r[length(r)]
M<-c(M,maxi)
fxi<-15*maxi^(14)
FXI<-c(FXI,fxi)
}
hist(M)
FXI
maxi
r
?dbeta
dbeta(maxi,15,1)
pbeta(maxi,15,1)
M
pbeta(M,15,1)
hist(pbeta(M,15,1))
j<-seq(1,15)
pbeta(r,j,16-j))
pbeta(r,j,16-j)
hist(pbeta(r,j,16-j))
j
r<-runif(15,min=0,max=1)
r<-r[order(r)]
hist(pbeta(r,seq(1,15),16-seq(1,15)))
r
r
?pbeta
9/71
1-exp(-0.0061*5)
knitr::opts_chunk$set(echo = TRUE)
library(ruv)
m = 50
n = 10000
nc = 1000
p = 1
k = 20
ctl = rep(FALSE, n)
ctl[1:nc] = TRUE
X = matrix(c(rep(0,floor(m/2)), rep(1,ceiling(m/2))), m, p)
beta = matrix(rnorm(p*n), p, n)
beta[,ctl] = 0
W = matrix(rnorm(m*k),m,k)
alpha = matrix(rnorm(k*n),k,n)
epsilon = matrix(rnorm(m*n),m,n)
Y = X%*%beta + W%*%alpha + epsilon
## Run RUV-4
fit = RUV4(Y, X, ctl, k)
## Get adjusted variances and p-values
fit = variance_adjust(fit)
make_residual_mat_several_rep<- function(data,clusters, norm_clus_list,samples,rep_samples_list){
#make_residual_mat(raw_Y,data$cluster, norm_clusters,norm_clusters_second,data$sample,rep_samples,second_rep_samples)
res_mat=data
res_mat[]=0
for (r in 1:length(rep_samples_list)){
norm_clus=norm_clus_list[[r]]
rep_samples=rep_samples_list[[r]]
mean_pseud=matrix(nrow = length(norm_clus),ncol=dim(data)[2])
for (i in 1:length(norm_clus)){
tmp=((clusters == norm_clus[i])&(samples%in%rep_samples))
mean_pseud[i,]=colMeans(data[tmp,])
res_mat[tmp,]<- t(apply(data[tmp,], 1, function(x) x-mean_pseud[i,]))
}
}
return(res_mat)
}
run_RUVIII <- function(data, norm_clusters, k,rep_samples){
raw_Y <- as.matrix(data[3:ncol(data)])
# Standardise the input and then compensate output
col_means <- colMeans(raw_Y)
col_sds <- apply(raw_Y, 2, function(x) sd(x))
for(i in 1:ncol(raw_Y)){
raw_Y[,i] <- (raw_Y[,i] - col_means[i])/col_sds[i]
}
# Run the actual RUVIII
res_mat<-make_residual_mat_several_rep(raw_Y,data$cluster, norm_clusters,data$sample,rep_samples)
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = k)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
return(norm_Y)
}
fastRUVIII = function(Y, M, ctl,res_mat,k=NULL, eta=NULL, average=FALSE, fullalpha=NULL){
# Assumes good input
if (!(k > 0)) stop("Bad input - read the documentation")
Y = ruv::RUV1(Y,eta,ctl)
m = nrow(Y)
#Y0 = fast_residop(Y, M)
Y0=res_mat
fullalpha = diag(rsvd(Y0)$d) %*% t(rsvd(Y0)$v)
alpha = fullalpha[1:k,,drop=FALSE]
ac = alpha[,ctl,drop=FALSE]
W = Y[,ctl] %*% t(ac) %*% solve(ac %*% t(ac))
newY = Y - W %*% alpha
return(list(newY = newY, fullalpha=fullalpha))
}
normalise_data<-function (data, raw_data, rep_samples, norm_clusters, k, num_clusters,
wd_data, dir_norm_data)
{
norm_cells <- run_RUVIII(raw_data, norm_clusters, k, rep_samples)
output_dir <- file.path(wd_data, dir_norm_data)
if (!dir.exists(output_dir)) {
dir.create(output_dir)
}
new_md = save_norm_files(data, norm_cells, data$fcs_raw,
data$md, data$panel, output_dir, k)
writexl::write_xlsx(new_md, path = file.path(output_dir,
"Norm_Metadata.xlsx"), col_names = TRUE, format_headers = TRUE)
writexl::write_xlsx(data$panel, path = file.path(output_dir,
"Norm_Panel.xlsx"), col_names = TRUE, format_headers = TRUE)
norm_setup = list(rep_samples = rep_samples, cluster_to_norm = norm_clusters,
k = k, metadata_norm = new_md)
saveRDS(norm_setup, file = file.path(output_dir, "Norm_setup.rds"))
saveRDS(norm_cells, file = file.path(output_dir, "Norm_data.rds"))
}
library(rsvd)
# save(data,file='~/GithubRepos/Rstudio-Github/data.RData')
load(file='~/GithubRepos/Rstudio-Github/data.RData')
## normalize call.
rep_samples=list( data$md$sample_id%>%unique%>%as.character())
library(rsvd)
# save(data,file='~/GithubRepos/Rstudio-Github/data.RData')
load(file='~/GithubRepos/Rstudio-Github/data.RData')
library(magrittr)
## normalize call.
rep_samples=list( data$md$sample_id%>%unique%>%as.character())
#normalise data:
#1: residual plot: for each rep_samples selected, and for each cluster formed, identifies the residual (deviance) from each cell in rep_samples to the average per cluster
# the resmat is a matrix, for each rep_sample cells, the difference between the cluster average for those replicates.
#2: uses these in RUVIII
#20 meta-clusters defined originally
cluster_list_rep_samples <- list(levels(cluster_ids(data$daf,'meta20')))
?cluster_ids
library(SingleCellExperiment)
cluster_list_rep_samples <- list(levels(cluster_ids(data$daf,'meta20')))
data
library(CytofRUV)
cluster_ids
library(flowSet)
library(flowCore)
cluster_ids
??cluster_ids
library(CATALYST)
## normalize call.
rep_samples=list( data$md$sample_id%>%unique%>%as.character())
#normalise data:
#1: residual plot: for each rep_samples selected, and for each cluster formed, identifies the residual (deviance) from each cell in rep_samples to the average per cluster
# the resmat is a matrix, for each rep_sample cells, the difference between the cluster average for those replicates.
#2: uses these in RUVIII
#20 meta-clusters defined originally
cluster_list_rep_samples <- list(levels(cluster_ids(data$daf,'meta20')))
k_value <- 10
seed=1234
## do by 'hand'
raw_data <- data.frame(sample = data$daf$sample_id, cluster=cluster_ids(data$daf,"meta20"), t(SummarizedExperiment::assay(data$daf,"exprs")))
raw_Y <- as.matrix(raw_data[,3:ncol(raw_data)])
# Standardise the input and then compensate output
col_means <- colMeans(raw_Y)
col_sds <- apply(raw_Y, 2, function(x) sd(x))
for(i in 1:ncol(raw_Y)){
raw_Y[,i] <- (raw_Y[,i] - col_means[i])/col_sds[i]
}
res_mat<-make_residual_mat_several_rep(raw_Y,raw_data$cluster, cluster_list_rep_samples,raw_data$sample,rep_samples)
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = 10)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
ny<-as.data.frame(norm_Y)
ny$sample<-raw_data$sample
ny$cluster<-raw_data$cluster
ny$batch<-data$md$batch[match(ny$sample,data$md$sample_id)]
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
head(ny)
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
head(PCi)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
library(ggplot2)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
## compare with normal.
pcs<-prcomp((raw_data[,3:ncol(raw_data)]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca2<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca2+geom_vline(xintercept=0.25,linetype='dashed'))
## re-cluster
colnames(ny)
colnames(dat$daf)
data
colnames(dta)
rownames(data)
1-e^(-0.02*3)
1-exp^(-0.02*3)
1-exp(-0.02*3)
1-exp(-0.01*3)
0.75*1.9
3000*0.0582
3000*0.0296
7000*0.0296
(175/3000)/(207/7000)
175*0.02
0.01*207
3.5/2.07
(175*6793)/(207*2825)
1.973/1.691
3000*0.02
r=0.02/0.01
r
3000*0.02
3.325^2
3.325*25/9
16.919*25/9
600*0.9
600*0.1
400*0.7
400*0.9
400*0.9
400*0.7
