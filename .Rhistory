geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch DNA variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = 10)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
ny<-as.data.frame(norm_Y)
ny$sample<-raw_data$sample
ny$cluster<-raw_data$cluster
ny$batch<-data$md$batch[match(ny$sample,data$md$sample_id)]
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch DNA variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
## do by 'hand'
raw_data <- data.frame(sample = data$daf$sample_id, cluster=cluster_ids(data$daf,"meta20"), t(SummarizedExperiment::assay(data$daf,"exprs")))
raw_Y <- as.matrix(raw_data[,3:ncol(raw_data)])
# Standardise the input and then compensate output
col_means <- colMeans(raw_Y)
col_sds <- apply(raw_Y, 2, function(x) sd(x))
for(i in 1:ncol(raw_Y)){
raw_Y[,i] <- (raw_Y[,i] - col_means[i])/col_sds[i]
}
res_mat<-make_residual_mat_several_rep(raw_Y,raw_data$cluster, cluster_list_rep_samples,raw_data$sample,rep_samples)
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = 15)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
ny<-as.data.frame(norm_Y)
ny$sample<-raw_data$sample
ny$cluster<-raw_data$cluster
ny$batch<-data$md$batch[match(ny$sample,data$md$sample_id)]
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch DNA variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
## do by 'hand'
raw_data <- data.frame(sample = data$daf$sample_id, cluster=cluster_ids(data$daf,"meta20"), t(SummarizedExperiment::assay(data$daf,"exprs")))
raw_Y <- as.matrix(raw_data[,3:ncol(raw_data)])
# Standardise the input and then compensate output
col_means <- colMeans(raw_Y)
col_sds <- apply(raw_Y, 2, function(x) sd(x))
for(i in 1:ncol(raw_Y)){
raw_Y[,i] <- (raw_Y[,i] - col_means[i])/col_sds[i]
}
res_mat<-make_residual_mat_several_rep(raw_Y,raw_data$cluster, cluster_list_rep_samples,raw_data$sample,rep_samples)
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = 5)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
ny<-as.data.frame(norm_Y)
ny$sample<-raw_data$sample
ny$cluster<-raw_data$cluster
ny$batch<-data$md$batch[match(ny$sample,data$md$sample_id)]
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch DNA variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
## do by 'hand'
raw_data <- data.frame(sample = data$daf$sample_id, cluster=cluster_ids(data$daf,"meta20"), t(SummarizedExperiment::assay(data$daf,"exprs")))
raw_Y <- as.matrix(raw_data[,3:ncol(raw_data)])
# Standardise the input and then compensate output
col_means <- colMeans(raw_Y)
col_sds <- apply(raw_Y, 2, function(x) sd(x))
for(i in 1:ncol(raw_Y)){
raw_Y[,i] <- (raw_Y[,i] - col_means[i])/col_sds[i]
}
res_mat<-make_residual_mat_several_rep(raw_Y,raw_data$cluster, cluster_list_rep_samples,raw_data$sample,rep_samples)
norm_Y <- fastRUVIII(Y = raw_Y, M, ctl = c(1:ncol(raw_Y)), res_mat=res_mat,k = 10)$newY
for(i in 1:ncol(norm_Y)){
norm_Y[,i] <- norm_Y[,i]*col_sds[i] + col_means[i]
}
ny<-as.data.frame(norm_Y)
ny$sample<-raw_data$sample
ny$cluster<-raw_data$cluster
ny$batch<-data$md$batch[match(ny$sample,data$md$sample_id)]
pcs<-prcomp((ny[,1:31]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
head(raw_data)
## compare with normal.
pcs<-prcomp((raw_data[,3:ncol(raw_data)]))
PCi<-data.frame(pcs$x,ROIID=ny$sample,batch=ny$batch)
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca2<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca2+geom_vline(xintercept=0.25,linetype='dashed'))
varz<-100*round(pcs$sdev/sum(pcs$sdev),3)
PCi$case<-factor(PCi$ROIID)
batch.pca2<- ggplot(PCi,aes(x=PC1,y=PC2,col=batch,label=batch))+
geom_point(size=2)+xlim(c( min(PCi$PC1)-0.05,  max(PCi$PC1)+0.05))+
theme_classic()+
xlab(paste0("PC1 (",varz[1],"%)"))+ylab(paste0("PC2 (",varz[2],"%)"))+
geom_text(aes(label=batch),hjust=0, vjust=0)+ggtitle("Batch variability")
print( batch.pca2+geom_vline(xintercept=0.25,linetype='dashed'))
print( batch.pca2+geom_vline(xintercept=0.25,linetype='dashed'))
print( batch.pca+geom_vline(xintercept=0.25,linetype='dashed'))
# this function reads CSV from histoCAT and creates an Robject of the spatial features
## FIXME: need a parameter for neighbour_ features, tSNE features, and Phenograph features.
readPhenoCase<-function(myPath=NULL,dropNeighborhooodAnalysis=TRUE){
# myPath is the directory to the histoCAT output csv files
#
output<-NULL
targs<-unique(dir(myPath))
for(i in targs){
print(i)
dat<-read.csv(paste0(myPath,"/",i))
if( any(grepl("Phenograph",colnames(dat)))==TRUE){
phenos<-colnames(dat)[grepl("Phenograph",colnames(dat))]
newphenoID<-unique(phenos)
}else{
dat[,'Phenograph']<-NA
}
if( any(grepl("tSNE",colnames(dat)))==TRUE){
tsnes<-colnames(dat)[grepl("tSNE",colnames(dat))]
newtsneID<-unique(tsnes)
}else{
dat[,'tSNE']<-NA
}
#if drop is true ignore neighbour_ columns, otherwise keep.
if(dropNeighborhooodAnalysis==TRUE){
mycolumns<-c("ImageId","CellId",
"Area",
"Eccentricity",
"Solidity",
"Extent",
"EulerNumber",
"Perimeter",
"MajorAxisLength",
"MinorAxisLength",
"Orientation",
"Percent_Touching",
"Number_Neighbors",
"X_position",
"Y_position",
newphenoID,
newtsneID)
}else{
nbhds<-colnames(dat)[grepl("neighbour_",colnames(dat))]
neighborID<-unique(nbhds)
mycolumns<-c("ImageId",
"CellId",
"Area",
"Eccentricity",
"Solidity",
"Extent",
"EulerNumber",
"Perimeter",
"MajorAxisLength",
"MinorAxisLength",
"Orientation",
"Percent_Touching",
"Number_Neighbors",
"X_position",
"Y_position",
newphenoID,
newtsneID,
neighborID)
}
markers<-colnames(dat)[grepl("Cell_",colnames(dat))]
myColumns<-c(mycolumns,markers)
dat<-dat[,myColumns]
dat$ROIID<- gsub(".csv","",i)
dat$uniqueLabel<-paste0(dat$ImageId,"_",dat$CellId)
### if there are columns in a specific case that do not match the previous calls, usually from histoCAT analysis.
if(!is.null(output)==TRUE){
if(any(!colnames(dat)%in%colnames(output))){
new<-colnames(dat)[!colnames(dat)%in%colnames(output)]
output[,new]<-NA
stopifnot(all(colnames(dat)%in%colnames(output)))
}
if(any(!colnames(output)%in%colnames(dat))){
new<-colnames(output)[!colnames(output)%in%colnames(dat)]
dat[,new]<-NA
stopifnot(all(colnames(output)%in%colnames(dat)))
}
}## checking if output is not null.
if(is.null(output)==TRUE){
output<-dat
}else{
output<-dplyr::bind_rows(output,dat)
}
dat<-NULL
} #for loop
return(output)
}
zScorePatientExpression<-function(full.dn4=NULL,markers=NULL,ROIID.column=NULL){
X3<-full.dn4[,c(markers,ROIID.column)]%>%group_by(ROIID)%>%summarise_all(funs(sd))%>%data.frame
X2<-full.dn4[,c(markers,ROIID.column)]%>%group_by(ROIID)%>%summarise_all(funs(mean))%>%data.frame
###
z<-full.dn4
for(cl in unique(full.dn4$ROIID)){
for(mark in colnames(X2)[-1]){
z[which(z$ROIID==cl),which(colnames(z)==mark)]<- ( z[which(z$ROIID==cl),which(colnames(z)==mark)]-X2[which(X2$ROIID==cl),which(colnames(X2)==mark)])/(X3[which(X3$ROIID==cl),which(colnames(X3)==mark)])
}
}
return(z)
}
metaClusterPhenotype<-function(dn4=NULL,phenotype=NULL,myPheno=NULL,markers=NULL,plotPCA=FALSE,k2=15){
#myPheno is the column for the phenotype.
erik<-subset(dn4,dn4[,myPheno]==phenotype)
## subMeta holds the casePheno
dn4[,paste0(phenotype,"_subMeta")]<-NA
erik[,paste0(phenotype,"_subMeta")]<-NA
require(Rphenograph)
roiData<-as.data.frame.matrix(table(erik$ROIID,erik[,myPheno]))
for(roi in rownames(roiData)[which(roiData[,phenotype]>45)]){
myroi<-subset(erik,erik$ROIID==roi)
graph<-Rphenograph(myroi[,markers],k=45)
myroi[,paste0(phenotype,"_subMeta")]<-membership(graph[[2]])
dn4[match(myroi$uniqueLabel,dn4$uniqueLabel),paste0(phenotype,"_subMeta")]<-membership(graph[[2]])
erik[match(myroi$uniqueLabel,erik$uniqueLabel),paste0(phenotype,"_subMeta")]<-membership(graph[[2]])
}
ErikMeta=erik[,
c(markers,
"ROIID",
paste0(phenotype,"_subMeta"))] %>% group_by(ROIID,.dots=paste0(phenotype,"_subMeta")) %>%
dplyr::summarise_all(funs(median)) %>%data.frame
##Levine used k=15 for meta.
erikPheno<- Rphenograph(ErikMeta[,c(markers)], k = k2)
subphenograph_cluster_meta<- factor(membership(erikPheno[[2]]))
table(subphenograph_cluster_meta)
ErikMeta=cbind(ErikMeta, subphenograph_cluster_meta)
### plot PCA, label each case.  COO,  status.  ##
if( any(colnames(erik)== paste0(phenotype,"_subphenograph_cluster_meta"))){
erik<-erik[,which(colnames(erik)!= paste0(phenotype,"_subphenograph_cluster_meta"))]
}
myLocal=left_join(erik, ErikMeta[,c("ROIID",paste0(phenotype,"_subMeta"),"subphenograph_cluster_meta")], by = c("ROIID"))
colnames(myLocal)[which(colnames(myLocal)=="subphenograph_cluster_meta")]<-paste0(phenotype,"_subphenograph_cluster_meta")
dn4[,paste0(phenotype,"_subphenograph_cluster_meta")]<-NA
dn4[match(myLocal$uniqueLabel,dn4$uniqueLabel),paste0(phenotype,"_subphenograph_cluster_meta")]<-myLocal[,which(colnames(myLocal)==paste0(phenotype,"_subphenograph_cluster_meta"))]
plot_clustering_heatmap_wrapper(expr=ErikMeta[,c(markers)],
cell_clustering=ErikMeta[,"subphenograph_cluster_meta"],
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
return(dn4)
}
plot_clustering_heatmap_wrapper<-function(expr=NULL,
cell_clustering=NULL, cluster_merging = NULL,useMedians=TRUE,useQuantiles=FALSE,
color_clusters=NULL){
## cluster_merging should be character merging vector of 29 or so clusters. this is input from the ANNOTATION object.  not a matched object level.
expr<-as.matrix(expr)
if(useQuantiles==TRUE){
##max min normalization
library(matrixStats)
rng <- colQuantiles(expr, probs = c(0.001, 0.999))
expr01 <- t((t(expr) - rng[, 1]) / (rng[, 2] - rng[, 1]))
expr01[expr01 < 0] <- 0
expr01[expr01 > 1] <- 1
}else{
expr01<-expr
}
if(is.null(color_clusters)==TRUE){
color_clusters <- c("#DC050C", "#FB8072", "#1965B0", "#7BAFDE", "#882E72",
"#B17BA6", "#FF7F00", "#FDB462", "#E7298A", "#E78AC3",
"#33A02C", "#B2DF8A", "#55A1B1", "#8DD3C7", "#A6761D",
"#E6AB02", "#7570B3", "#BEAED4", "#666666", "#999999",
"#aa8282", "#d4b7b7", "#8600bf", "#ba5ce3", "#808000",
"#aeae5c", "#1e90ff", "#00bfff", "#56ff0d", "#ffff00")
}
# Calculate the median expression
library(dplyr)
expr_median <- data.frame(expr, cell_clustering = cell_clustering) %>%
dplyr::group_by(cell_clustering) %>%
dplyr::summarize_all(funs(median))
if(useMedians==TRUE){
expr01_median <- data.frame(expr01, cell_clustering = cell_clustering) %>%
group_by(cell_clustering) %>%
dplyr::summarize_all(funs(median))
}else{
expr01_median <- data.frame(expr01, cell_clustering = cell_clustering) %>%
dplyr::group_by(cell_clustering) %>%
dplyr::summarize_all(funs(mean))
}
# Calculate cluster frequencies
clustering_table <- as.numeric(table(cell_clustering))
print(dim(expr_median))
# This clustering is based on the markers that were used for the main clustering
d <- dist(expr_median[, colnames(expr)], method = "euclidean")
cluster_rows <- hclust(d, method = "average")
expr_heat <- as.matrix(expr01_median[, colnames(expr01)])
rownames(expr_heat) <- expr01_median$cell_clustering
labels_row <- paste0(rownames(expr_heat), " (",
round(clustering_table / sum(clustering_table) * 100, 2), "%)")
labels_col <- colnames(expr_heat)
# Row annotation for the heatmap
annotation_row <- data.frame(cluster = factor(expr01_median$cell_clustering))
rownames(annotation_row) <- rownames(expr_heat)
color_clusters <- color_clusters[1:nlevels(annotation_row$cluster)]
names(color_clusters) <- levels(annotation_row$cluster)
annotation_colors <- list(cluster = color_clusters)
annotation_legend <- FALSE
if(!is.null(cluster_merging)){
annotation_row$cluster_merging <- factor(cluster_merging)
color_clusters <- color_clusters[1:nlevels(factor(cluster_merging))]
names(color_clusters) <- levels(factor(cluster_merging))
annotation_colors$cluster_merging <- color_clusters
annotation_legend <- TRUE
}
# Colors for the heatmap
library(RColorBrewer);library(pheatmap)
color <- colorRampPalette(rev(brewer.pal(n = 9, name = "RdYlBu")))(100)
pheatmap::pheatmap(expr_heat, color = color,
cluster_cols = FALSE, cluster_rows = cluster_rows,
labels_col = labels_col, labels_row = labels_row,
display_numbers = TRUE, number_color = "black",
fontsize = 10, fontsize_number = 7,
annotation_row = annotation_row, annotation_colors = annotation_colors,
annotation_legend = annotation_legend)
}
mynormalize<-function(data=NULL,percentile=NULL){
if(percentile>1){
percentile<-percentile/100
}
if(is.null(percentile)==TRUE){
minValues<-apply(data,2,min)
maxValues<-apply(data,2,max)
}else{
minValues<-apply(data,2,function(x) quantile(x,1-percentile)  )
maxValues<-apply(data,2,function(x) quantile(x,percentile)  )
}
hv2<-maxValues-minValues
dataXR<-data
stopifnot(all( colnames(data)==names(minValues)))
stopifnot(all(colnames(data)==names(maxValues)))
stopifnot(all(colnames(data)==names(hv2)))
for(j in 1:ncol(data)){
dataXR[,j]<-(data[,j]-minValues[j])/hv2[j]
}
dataXR[dataXR<0]<-0
dataXR[dataXR>1]<-1
is.nand<-apply(dataXR,2,function(x) any(is.nan(x)))
for(i in which(is.nand)){
id<- which(is.na(dataXR[,i]))
dataXR[id,i]<-0
}
is.nad<-apply(dataXR,2,function(x) any(is.na(x)))
for(i in which(is.nad)){
id<- which(is.na(dataXR[,i]))
dataXR[id,i]<-0
}
# dataXR[which(is.na(dataXR))]<-0
stopifnot(all(apply(dataXR,2,max)==1))
stopifnot(all(apply(dataXR,2,min)==0))
return(dataXR)
}
dim(ny)
head(ny)
colnames(ny)
plot_clustering_heatmap_wrapper(expr=ny[,1:31],
cell_clustering=ny$cluster,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
lineage
induc
plot_clustering_heatmap_wrapper(expr=ny[,c(lineage,induc)],
cell_clustering=ny$cluster,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
plot_clustering_heatmap_wrapper(expr=ny[,colnames(ny)%in%c(lineage,induc)],
cell_clustering=ny$cluster,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
percentilenormalize()
percentilenormalize
ny.mm<-percentilenormalize(data=ny[,1:31],percentile=0.99)
plot_clustering_heatmap_wrapper(expr=ny.mm,
cell_clustering=ny$cluster,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
plot_clustering_heatmap_wrapper(expr=ny.mm,
cell_clustering=ny$batch,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
table(ny$sample,ny$cluster)
ny.mm<-percentilenormalize(data=ny[,1:31],percentile=0.99)
plot_clustering_heatmap_wrapper(expr=ny.mm,
cell_clustering=ny$cluster,
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
head(ny)
ggplot(ny,aes(x=batch,y=Cell_Histone3_Yb171))+geom_boxplot()
ggplot(ny,aes(x=batch,y= Cell_Reolysin_Gd160))+geom_boxplot()
ggplot(raw_data,aes(x=batch,y= Cell_Reolysin_Gd160))+geom_boxplot()
head(raw_data)
dim(raw_data)
dim(ny)
raw_data$batch<-ny$batch
ggplot(raw_data,aes(x=batch,y= Cell_Reolysin_Gd160))+geom_boxplot()
norm_data
data
?cluster_data
dim(nnorm_coords())
dim(norm_Y
)
head(norm_Y)
norm_data<-data$daf
norm_data
assay(norm_data
)
assay(norm_data)$exprs%>%dim
assay(norm_data)%>%dim
assay(norm_data)<-t(norm_Y)
norm_data
lineage
norm_data=cluster_data(norm_data,seed,markers_to_use=lineage,clusters_nb)
get_features(norm_data)
lineage
rownames(norm_data)
clusters_nb
library(CytofRUV)
norm_data=cluster_data(norm_data,seed,markers_to_use=lineage,clusters_nb)
cluster_data(data,seed,markers_to_use=lineage,clusters_nb)
data$lineage_markers
norm_data=cluster_data(norm_data,seed,markers_to_use=data$lineage_markers,clusters_nb)
norm_data
ny.mm<-percentilenormalize(data=ny[,1:31],percentile=0.99)
plot_clustering_heatmap_wrapper(expr=ny.mm,
cell_clustering=cluster_ids(norm_data,'meta20'),
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
plot_clustering_heatmap_wrapper(expr=t(assay(norm_data)),
cell_clustering=cluster_ids(norm_data,'meta20'),
useMedians=TRUE,
useQuantiles=FALSE,
color_clusters=NULL)
head(ny.mm)
ny.mm$mc<-cluster_ids(norm_data,'meta20')
ny.mm$ROIID<-ny$sample
head(ny.mm)
table(ny.mm$mc,ny.mm$ROIID)
as.data.frame.matrix(table(ny.mm$mc,ny.mm$ROIID))
x<-as.data.frame.matrix(table(ny.mm$mc,ny.mm$ROIID))
head(x)
x<-100*(x/rowSums(x))
x
norm_data
data$md
daf=norm_data
md=data$md
seed=1234
# Number of cells for diagnostic plots marker specific
n_subset_marker_specific <- 10000
# Define type of markers
daf_type <- daf[SingleCellExperiment::rowData(daf)$marker_class=="type", ]
daf_state <- daf[SingleCellExperiment::rowData(daf)$marker_class=="state", ]
sub_daf_state <- daf_state[, sample(ncol(daf_state), n_subset_marker_specific)]
sub_daf_type <- daf_type[, sample(ncol(daf_type), n_subset_marker_specific)]
sub_daf_type
daf_type
rowData(daf)
batch_ids <- is.factor(rep(md$batch, nrow(daf)))
sampleID_sorted <- md$sample_id[order(md$patient_id)]
batch_ids
md$batch
set.seed(seed)
# Number of cells for tSNE plots marker specific
TSNE_subset <- 1000
print("Running TSNE")
daf <- runDR(daf, "TSNE", cells = TSNE_subset)
# Number of cells for UMAP plots marker specific
UMAP_subset <- 1500
print("Running UMAP")
daf <- runDR(daf, "UMAP", cells = UMAP_subset)
# Launch Shiny
# For a subset of the data, define the number of cells for diagnostic plots
n_subset <- 1500
sub_daf <- daf[, sample(ncol(daf), n_subset)]
# # For the full dataset:
# sub_daf <- daf
panel=data$panel
CytofRUV::launch_Shiny(daf)
